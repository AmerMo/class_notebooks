{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced techniques\n",
    "\n",
    "Let's explore feature engineering techniques with the house prices dataset from Kaggle.\n",
    "\n",
    "We can find an illustrative example of how to use Deep feature synthesis [here](https://www.kaggle.com/willkoehrsen/featuretools-for-good), and a good explanation [here](https://stackoverflow.com/questions/52418152/featuretools-can-it-be-applied-on-a-single-table-to-generate-features-even-when).\n",
    "\n",
    "To Do\n",
    "- Group some features together (business domain)\n",
    "- Find categories under-represented (beyond current proposed method)\n",
    "- ~~Scale numerical features~~\n",
    "- Onehot/Label binarize encode categorical features (option)\n",
    "- Baseline the model with a multiple linear regression and high degree polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Advanced-techniques\" data-toc-modified-id=\"Advanced-techniques-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Advanced techniques</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup-the-dataset\" data-toc-modified-id=\"Setup-the-dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Setup the dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scale-numerical-features\" data-toc-modified-id=\"Scale-numerical-features-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Scale numerical features</a></span></li><li><span><a href=\"#Check-skewness\" data-toc-modified-id=\"Check-skewness-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Check skewness</a></span></li><li><span><a href=\"#Check-correlation\" data-toc-modified-id=\"Check-correlation-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Check correlation</a></span></li><li><span><a href=\"#Under-represented-features\" data-toc-modified-id=\"Under-represented-features-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Under represented features</a></span></li></ul></li><li><span><a href=\"#Deep-Feature-Synthesis\" data-toc-modified-id=\"Deep-Feature-Synthesis-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Deep Feature Synthesis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Build-the-EntitySet\" data-toc-modified-id=\"Build-the-EntitySet-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Build the EntitySet</a></span></li><li><span><a href=\"#Normalize-the-entity\" data-toc-modified-id=\"Normalize-the-entity-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Normalize the entity</a></span></li><li><span><a href=\"#Deep-feature-synthesis\" data-toc-modified-id=\"Deep-feature-synthesis-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Deep feature synthesis</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import skew, boxcox_normmax\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "from src.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available types: [dtype('int64') dtype('O') dtype('float64')]\n",
      "80 Features\n",
      "43 categorical features\n",
      "37 numerical features\n",
      "16 categorical features with NAs\n",
      "0 numerical features with NAs\n",
      "64 Complete features\n",
      "--\n",
      "Target: Not set\n"
     ]
    }
   ],
   "source": [
    "houses = Dataset('./data/houseprices_prepared.csv.gz')\n",
    "houses.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will replace the NA's in the dataset with 'None' or 'Unknown' since they're not really NA's. For no good reason the person in charge of encoding the file decided to assign NA's to values where the feature does not apply, but instead of using a value for that special condition (like the string 'None') he/she decided to use the actual NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available types: [dtype('int64') dtype('O') dtype('float64')]\n",
      "79 Features\n",
      "43 categorical features\n",
      "36 numerical features\n",
      "0 categorical features with NAs\n",
      "0 numerical features with NAs\n",
      "79 Complete features\n",
      "--\n",
      "Target: SalePrice\n"
     ]
    }
   ],
   "source": [
    "houses.replace_na(column='Electrical', value='Unknown')\n",
    "houses.replace_na(column=houses.names('categorical_na'), value='None')\n",
    "houses.set_target('SalePrice')\n",
    "houses.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale numerical features\n",
    "\n",
    "Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "\n",
    "In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.\n",
    "\n",
    "For instance, many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) assume that all features are centered around zero and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available types: [dtype('float64') dtype('O')]\n",
      "79 Features\n",
      "43 categorical features\n",
      "36 numerical features\n",
      "0 categorical features with NAs\n",
      "0 numerical features with NAs\n",
      "79 Complete features\n",
      "--\n",
      "Target: SalePrice\n"
     ]
    }
   ],
   "source": [
    "houses.scale()\n",
    "houses.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check skewness\n",
    "\n",
    "In many modeling scenarios, normality of the features in a dataset is desirable. Power transforms are a family of parametric, monotonic transformations that aim to map data from any distribution to as close to a Gaussian distribution as possible in order to stabilize variance and minimize skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available types: [dtype('float64') dtype('O')]\n",
      "79 Features\n",
      "43 categorical features\n",
      "36 numerical features\n",
      "0 categorical features with NAs\n",
      "0 numerical features with NAs\n",
      "79 Complete features\n",
      "--\n",
      "Target: SalePrice\n"
     ]
    }
   ],
   "source": [
    "houses.ensure_normality()\n",
    "houses.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numericals_to_drop, corr_num = houses.numerical_correlated(threshold=0.7)\n",
    "print('There are {} correlated columns to remove.'.format(\n",
    "    len(numericals_to_drop)))\n",
    "print(numericals_to_drop)\n",
    "houses.plot_corr_matrix(corr_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals_to_drop, corr_categ = houses.categorical_correlated(threshold=0.7)\n",
    "print('There are {} correlated columns to remove.'.format(\n",
    "    len(categoricals_to_drop)))\n",
    "print(categoricals_to_drop)\n",
    "houses.plot_corr_matrix(corr_categ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.drop_columns(categoricals_to_drop + numericals_to_drop)\n",
    "houses.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under represented features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "urf = houses.under_represented_features()\n",
    "print('Features with unrepresented categories:\\n', urf)\n",
    "houses.drop_columns(urf)\n",
    "print(end='')\n",
    "houses.describe();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Feature Synthesis\n",
    "### Build the EntitySet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "\n",
    "es = ft.EntitySet()\n",
    "es = es.entity_from_dataframe(entity_id='houses', \n",
    "                              dataframe=houses.data,\n",
    "                              index = 'Id')\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es.normalize_entity(base_entity_id='houses', \n",
    "                    new_entity_id='houses_norm',\n",
    "                    additional_variables = houses.names('all').remove('Id'),\n",
    "                    index='Id')\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep feature synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_matrix, f_defs = ft.dfs(entityset=es,\n",
    "                          target_entity='houses_norm', \n",
    "                          n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove new variables that might be related to the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = []\n",
    "for col in f_matrix:\n",
    "    if col == houses.target.name:\n",
    "        pass\n",
    "    else:\n",
    "        if houses.target.name in col:\n",
    "            drop_cols.append(col)\n",
    "            \n",
    "print('Need to drop columns:', drop_cols)\n",
    "f_matrix = f_matrix[[x for x in f_matrix if x not in drop_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
